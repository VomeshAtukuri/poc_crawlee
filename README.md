
---

# ğŸ•·ï¸ AI-Powered Web Crawler & Q\&A System
A full-stack application that crawls websites, stores extracted content in a vector database (**LanceDB**), and allows users to ask questions with context-aware, AI-generated answers.

---

## ğŸ“Œ Overview

This project is a combination of **web scraping**, **vector search**, and **AI-driven Q\&A**, built using modern web technologies.

> **Goal:** Allow users to crawl any public website, extract meaningful content, store it semantically, and interact with that content via natural language queries.

---

## ğŸ§± Architecture

**Frontend**:
Built with **React + Vite**, the UI lets users input a URL for crawling and ask questions.

**Backend**:
Runs on **Fastify**, handles crawling via **PlaywrightCrawler**, processes content with **embedding models**, stores data in **LanceDB**, and returns intelligent answers using a vector search + LLM combo.

```
             +---------------+
             |    Frontend  |
             |  React + Vite  |
             +---------------+
                       |
                       |
                       v
             +---------------+
             |  Fastify API  |
             |  /crawl /chat  |
             +---------------+
                       |
                       |
                       v
             +---------------+
             | PlaywrightCrawler|
             |  Extract Text Data|
             +---------------+
                       |
                       |
                       v
             +---------------+
             |  Embedding Model  |
             | (e.g. OpenAI / Groq)|
             +---------------+
                       |
                       |
                       v
             +---------------+
             |     LanceDB (VDB)  |
             +---------------+

---

## âœ¨ Features

âœ… Crawl any public website using headless browser
âœ… Extract meaningful page content (skips scripts, styles, boilerplate)
âœ… Embed data into vectors using state-of-the-art LLMs
âœ… Store and query with **LanceDB**
âœ… Ask natural language questions and get contextually relevant answers
âœ… Built on a **scalable**, **modular**, and **modern** full-stack setup

---

## ğŸ› ï¸ Tech Stack

| Layer        | Tech                         |
| ------------ | ---------------------------- |
| Frontend     | React, Vite, TypeScript      |
| Backend      | Fastify, Node.js, TypeScript |
| Crawler      | Crawlee (PlaywrightCrawler)  |
| Vector Store | LanceDB                      |
| Embedding    | OpenAI / Groq                |

---

## ğŸ“‚ Folder Structure

```
my-crawlee/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ index.ts            # Fastify server setup
â”‚   â”œâ”€â”€ crawler.ts          # Website crawling logic
â”‚   â”œâ”€â”€ embed.ts            # Embedding + AI integration
â”‚   â”œâ”€â”€ lancedb.ts          # LanceDB operations
â”‚   â””â”€â”€ routes/             # API route handlers
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx         # Main React component
â”‚   â”‚   â”œâ”€â”€ components/     # UI components
â”‚   â”‚   â”œâ”€â”€ api.ts          # API integration
â”‚   â””â”€â”€ vite.config.ts      # Vite setup
```

---

## âš™ï¸ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/vomeshatukuri/poc_crawlee.git
cd my-crawlee
```

### 2. Install Dependencies

**Backend**

```bash
cd backend
npm install
```

**Frontend**

```bash
cd ../frontend
npm install
```

### 3. Environment Setup

In `backend/`, create a `.env` file:

```env
GROQ_API_KEY = your_groq_or_openai_key
```

### 4. Start Development Servers

**Start Backend**

```bash
cd backend
npm start
```

**Start Frontend**

```bash
cd ../frontend
npm run dev
```

---

## ğŸ’¡ Usage Guide

1. Enter a URL in the frontend.
2. Backend crawls and processes the content.
3. Content is stored as vector embeddings in LanceDB.
4. Ask a question based on the crawled site.
5. AI generates a context-aware answer using vector similarity search.

---

## ğŸ§  Example Use Cases

* ğŸ” Competitor website analysis
* ğŸ“š Knowledge base ingestion & querying
* ğŸ“° News site summarization and Q\&A
* ğŸ› ï¸ Internal tool for crawling documentation sites

---

## ğŸš§ Future Enhancements

* ğŸ›¡ï¸ User authentication and usage limits
* ğŸŒ Crawl multi-page or entire domains
* ğŸ§© Add summarization and topic tagging
* ğŸ“Š Visualize crawl data insights
* âš™ï¸ Docker + CI/CD support
